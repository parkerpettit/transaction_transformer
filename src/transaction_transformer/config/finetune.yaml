model:
  mode: "finetune"
  row_types: 1
  freeze_embedding: false
  pretrain_checkpoint_dir: "data/models/pretrained"
  finetune_checkpoint_dir: "data/models/finetuned"
  log_dir: "logs"
  
  field_transformer:
    d_model: 72
    n_heads: 8
    depth: 1
    ffn_mult: 4
    dropout: 0.1
    layer_norm_eps: 1.0e-6
    norm_first: false
  
  sequence_transformer:
    d_model: 1080
    n_heads: 12
    depth: 12
    ffn_mult: 4
    dropout: 0.1
    layer_norm_eps: 1.0e-6
    norm_first: false
  
  classification:
    hidden_dim: 512
    depth: 2  # Number of hidden layers in the MLP. 0 is a linear layer
    dropout: 0.1
    output_dim: 1

  embedding:
    emb_dim: 72
    dropout: 0.1
    padding_idx: 0
    freq_encoding_L: 8
    mask_token_init_std: 0.02
  
  training:
    total_epochs: 10
    batch_size: 128 
    learning_rate: 5.0e-5
    model_type: "mlm"  # "mlm" or "ar"
    optimizer: "adamw"
    scheduler: "cosine"
    mixed_precision: true
    amp_dtype: bf16
    grad_clip_norm: 1.0
    early_stopping_patience: 5
    max_batches_per_epoch: null  # null for full epoch; integer for debug cap
    device: "cuda"
    num_workers: 4
    positive_weight: 9.08  # Weight for positive (fraud) class. if 1.0, calculate from data
    # Finetune startup / resume control (deprecated in favor of W&B artifacts)
    resume: false
    resume_path: null
    from_scratch: false
    # Prefer W&B artifact; if omitted, code will auto-discover the latest pretrain artifact in this project.
    # You can still provide a local path to override.
    pretrained_backbone_path: null
    #   Label statistics from full_processed.pt with include_all_fraud: true
    #   Positive samples: 20677
    #   Negative samples: 1704227
    #   Positive ratio: 0.0120
    #   Recommended weights:
    #   Inverse frequency: 82.42
    #   Sqrt inverse frequency: 9.08
    # Recommended: Calculate as negative_samples / positive_samples from your dataset
    # Or use sqrt(negative_samples / positive_samples) for less aggressive weighting
  
  data:
    preprocessed_path: "data/processed/full_processed.pt"  # local override bundle (optional)
    use_local_inputs: false
    raw_csv_path: "data/raw/card_transaction.v1.csv"
    raw_artifact_name: "raw-card-transactions-v1"
    preprocessed_artifact_name: "preprocessed-card-v1"
    window: 10
    stride: 10
    num_bins: 100
    group_by: "User"
    include_all_fraud: true
    padding_idx: 0
    mask_idx: 1
    unk_idx: 2
    ignore_idx: -100

metrics:
  run_name: finetune
  wandb: true
  wandb_project: "transaction-transformer"
  wandb_entity: null
  seed: 42
  deterministic: false
  log_gradients: false
  log_parameters: false
